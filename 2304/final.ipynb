{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Syntatic Parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Syntactic parsing refers to a technique by which **tokenized, segmented and part-of-speech segmented text** is assigned a structure revealing the relationship between tokens\n",
    "- done as the **first step** in **deep information extraction** and semantic understanding of a text.\n",
    "- usually suffer from structural ambiguity : which means that we could have **more than one correct parse trees** for one sentence. This may present a challenge to selecting the most likely parse for the sentence. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chunking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Shallow parsing, also known as chunking, is a type of (NLP) technique that aims to identify and extract meaningflul phrases or chunks from a sentence. \n",
    "- shallow parsing focuses on identifying **individual phrases** or **constituents**, such as noun phrases, verb phrases, and prepositional phrases. \n",
    "- **constituents** are then linked to the higher order units with discrete grammatical meanings such as noun groups, verb groups, etc. \n",
    "\n",
    "- text --> groups(Noun Phrases)\n",
    "- group of words that you create from chunking is known as chunks\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('John', 'NNP'), ('found', 'VBD'), ('a', 'DT'), ('new', 'JJ'), ('coach', 'NN'), ('and', 'CC'), ('a', 'DT'), ('new', 'JJ'), ('bed', 'NN'), ('in', 'IN'), ('his', 'PRP$'), ('new', 'JJ'), ('apartment', 'NN')]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,592.0,168.0\" width=\"592px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"8.10811%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">John</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.05405%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"9.45946%\" x=\"8.10811%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">found</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.8378%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"21.6216%\" x=\"17.5676%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.5%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"31.25%\" x=\"25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.625%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"43.75%\" x=\"56.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">coach</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"78.125%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"28.3784%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"39.1892%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.5676%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"18.9189%\" x=\"45.9459%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"28.5714%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"14.2857%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"35.7143%\" x=\"28.5714%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"46.4286%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"35.7143%\" x=\"64.2857%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">bed</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.1429%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.4054%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.40541%\" x=\"64.8649%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.5676%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.10811%\" x=\"70.2703%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">his</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.3243%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"21.6216%\" x=\"78.3784%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"31.25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.625%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"68.75%\" x=\"31.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">apartment</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"89.1892%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('John', 'NNP'), ('found', 'VBD'), Tree('NP', [('a', 'DT'), ('new', 'JJ'), ('coach', 'NN')]), ('and', 'CC'), Tree('NP', [('a', 'DT'), ('new', 'JJ'), ('bed', 'NN')]), ('in', 'IN'), ('his', 'PRP$'), Tree('NP', [('new', 'JJ'), ('apartment', 'NN')])])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from textblob import TextBlob\n",
    "\n",
    "my_string = \"John found a new coach and a new bed in his new apartment.\"\n",
    "\n",
    "opt = TextBlob(my_string)\n",
    "\n",
    "print(opt.tags)\n",
    "\n",
    "#We are looking for zero or one determiner, \n",
    "#followed by one or more adjectives followed by a noun\n",
    "reg_exp = \"NP:{<DT>?<JJ>*<NN>}\"\n",
    "\n",
    "rp = nltk.chunk.RegexpParser(reg_exp)\n",
    "output = rp.parse(opt.tags)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chinking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After breaking down our text to chunks, we need to remove unwanted words from our chunks, In such a case, chinking is used.\n",
    "- Chinking is simply a process that you use to remove a chunk from a chunk\n",
    "- we denoted the chunks using `{}`. To denote the chinks, we use `}{` in the regular expression part.\n",
    "- If the sequence of tokens appears in the middle of the chunk, these tokens are removed, leaving two chunks where there was only one before. \n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,592.0,168.0\" width=\"592px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"8.10811%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">John</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"4.05405%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"9.45946%\" x=\"8.10811%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">found</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"12.8378%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.40541%\" x=\"17.5676%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.2703%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"22.973%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"26.3514%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"9.45946%\" x=\"29.7297%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">coach</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"34.4595%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"39.1892%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.5676%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.40541%\" x=\"45.9459%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.6486%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"51.3514%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"54.7297%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"58.1081%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">bed</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"61.4865%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.40541%\" x=\"64.8649%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.5676%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.10811%\" x=\"70.2703%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">his</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"74.3243%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.75676%\" x=\"78.3784%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"81.7568%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"14.8649%\" x=\"85.1351%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">apartment</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.5676%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [Tree('NP', [('John', 'NNP')]), ('found', 'VBD'), Tree('NP', [('a', 'DT')]), Tree('NP', [('new', 'JJ')]), Tree('NP', [('coach', 'NN')]), Tree('NP', [('and', 'CC')]), Tree('NP', [('a', 'DT')]), Tree('NP', [('new', 'JJ')]), Tree('NP', [('bed', 'NN')]), ('in', 'IN'), Tree('NP', [('his', 'PRP$')]), Tree('NP', [('new', 'JJ')]), Tree('NP', [('apartment', 'NN')])])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_exp = r\"\"\"\n",
    "NP: \n",
    "{<.*>} # chunking \n",
    "}<VBD|IN>+{ # chinking\n",
    "\"\"\"\n",
    "\n",
    "rp = nltk.chunk.RegexpParser(reg_exp)\n",
    "\n",
    "output = rp.parse(opt.tags)\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"168px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight: normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,912.0,168.0\" width=\"912px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">S</text></svg><svg width=\"5.26316%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">John</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NNP</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"2.63158%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"6.14035%\" x=\"5.26316%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">found</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"8.33333%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.50877%\" x=\"11.4035%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"13.1579%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10.5263%\" x=\"14.9123%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">coach</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.1754%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.38596%\" x=\"25.4386%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"27.6316%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.50877%\" x=\"29.8246%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">a</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"31.5789%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.77193%\" x=\"33.3333%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">bed</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"37.7193%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.50877%\" x=\"42.1053%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">in</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">IN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"43.8596%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"5.26316%\" x=\"45.614%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">his</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">PRP$</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.2456%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"14.0351%\" x=\"50.8772%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"31.25%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">new</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">JJ</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15.625%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"68.75%\" x=\"31.25%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">apartment</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65.625%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"57.8947%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"4.38596%\" x=\"64.9123%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">and</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">CC</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"67.1053%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"8.77193%\" x=\"69.2982%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"50%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"50%\" x=\"50%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">cat</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"73.6842%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"7.89474%\" x=\"78.0702%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">escaped</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">VBD</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.0175%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"3.50877%\" x=\"85.9649%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">to</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">TO</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"87.7193%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"10.5263%\" x=\"89.4737%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NP</text></svg><svg width=\"41.6667%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">the</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">DT</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.8333%\" y1=\"19.2px\" y2=\"48px\" /><svg width=\"58.3333%\" x=\"41.6667%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">house</text></svg><svg width=\"100%\" x=\"0%\" y=\"48px\"><defs /><svg width=\"100%\" x=\"0\" y=\"0px\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"16px\">NN</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.8333%\" y1=\"19.2px\" y2=\"48px\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"94.7368%\" y1=\"19.2px\" y2=\"48px\" /></svg>"
      ],
      "text/plain": [
       "Tree('S', [('John', 'NNP'), ('found', 'VBD'), ('a', 'DT'), Tree('NP', [('new', 'JJ'), ('coach', 'NN')]), ('and', 'CC'), ('a', 'DT'), Tree('NP', [('new', 'JJ'), ('bed', 'NN')]), ('in', 'IN'), ('his', 'PRP$'), Tree('NP', [('new', 'JJ'), ('apartment', 'NN')]), ('and', 'CC'), Tree('NP', [('the', 'DT'), ('cat', 'NN')]), ('escaped', 'VBD'), ('to', 'TO'), Tree('NP', [('the', 'DT'), ('house', 'NN')])])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_string = \"John found a new coach and a new bed in his new apartment and the cat escaped to the house\"\n",
    "opt = TextBlob(my_string)\n",
    "\n",
    "reg_exp = r\"\"\" \n",
    "NP: \n",
    "{(<JJ>{1,2}<NN>{1,2})|(<DT>{1,2}<NN>{1,2})} # chunking \n",
    "}<VBD|IN>+{ # chinking\n",
    "\"\"\"\n",
    "rp = nltk.chunk.RegexpParser(reg_exp)\n",
    "output = rp.parse(opt.tags)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PDFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total pages : 5\n"
     ]
    }
   ],
   "source": [
    "# Reading a PDF and printing it's pages \n",
    "pdf_bin = open(\"sample.pdf\", \"rb\")\n",
    "\n",
    "# read the object \n",
    "pdf_reader_obj = PyPDF2.PdfReader(pdf_bin)\n",
    "\n",
    "# print pages \n",
    "print(f\"total pages : {len(pdf_reader_obj.pages)}\")\n",
    "\n",
    "text = \"\"\n",
    "\n",
    "# extract text from the pdf \n",
    "for page in range(len(pdf_reader_obj.pages)):\n",
    "    \n",
    "    page_object = pdf_reader_obj.pages[page]\n",
    "    \n",
    "    page_text = page_object.extract_text()\n",
    "    \n",
    "    text += page_text\n",
    "    \n",
    "\n",
    "pdf_bin.close()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "seek of closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m writer \u001b[38;5;241m=\u001b[39m PyPDF2\u001b[38;5;241m.\u001b[39mPdfWriter()\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# add page to the writer \u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage_one\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m## Add Page ## \u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# read a dummy pdf \u001b[39;00m\n\u001b[1;32m     12\u001b[0m pdf_out_bin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/_writer.py:321\u001b[0m, in \u001b[0;36mPdfWriter.add_page\u001b[0;34m(self, page, excluded_keys)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_page\u001b[39m(\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    308\u001b[0m     page: PageObject,\n\u001b[1;32m    309\u001b[0m     excluded_keys: Iterable[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m (),\n\u001b[1;32m    310\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m PageObject:\n\u001b[1;32m    311\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;124;03m    Add a page to this PDF file.\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[38;5;124;03m    Recommended for advanced usage including the adequate excluded_keys\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[38;5;124;03m        an instance of :class:`PageObject<PyPDF2._page.PageObject>`\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mappend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcluded_keys\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/_writer.py:271\u001b[0m, in \u001b[0;36mPdfWriter._add_page\u001b[0;34m(self, page, action, excluded_keys)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 271\u001b[0m page \u001b[38;5;241m=\u001b[39m cast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPageObject\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mpage_org\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexcluded_keys\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m# page_ind = self._add_object(page)\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m page_org\u001b[38;5;241m.\u001b[39mpdf \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_data_structures.py:181\u001b[0m, in \u001b[0;36mDictionaryObject.clone\u001b[0;34m(self, pdf_dest, force_duplicate, ignore_fields)\u001b[0m\n\u001b[1;32m    179\u001b[0m     ignore_fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d__\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[43md__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_dest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_duplicate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d__\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_data_structures.py:243\u001b[0m, in \u001b[0;36mDictionaryObject._clone\u001b[0;34m(self, src, pdf_dest, force_duplicate, ignore_fields)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m[NameObject(k)] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 243\u001b[0m             \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_dest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_duplicate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    246\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_data_structures.py:181\u001b[0m, in \u001b[0;36mDictionaryObject.clone\u001b[0;34m(self, pdf_dest, force_duplicate, ignore_fields)\u001b[0m\n\u001b[1;32m    179\u001b[0m     ignore_fields \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(d__\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 181\u001b[0m     \u001b[43md__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_clone\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpdf_dest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_duplicate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d__\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_data_structures.py:243\u001b[0m, in \u001b[0;36mDictionaryObject._clone\u001b[0;34m(self, src, pdf_dest, force_duplicate, ignore_fields)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;28mself\u001b[39m[NameObject(k)] \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 243\u001b[0m             \u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_dest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforce_duplicate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_fields\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(v, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    245\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m    246\u001b[0m         )\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_base.py:247\u001b[0m, in \u001b[0;36mIndirectObject.clone\u001b[0;34m(self, pdf_dest, force_duplicate, ignore_fields)\u001b[0m\n\u001b[1;32m    245\u001b[0m     dup \u001b[38;5;241m=\u001b[39m pdf_dest\u001b[38;5;241m.\u001b[39mget_object(pdf_dest\u001b[38;5;241m.\u001b[39m_id_translated[\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpdf)][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39midnum])\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 247\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    248\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     dup \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39mclone(pdf_dest, force_duplicate, ignore_fields)\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/generic/_base.py:259\u001b[0m, in \u001b[0;36mIndirectObject.get_object\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_object\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPdfObject\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 259\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_object\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/main_env/lib/python3.12/site-packages/PyPDF2/_reader.py:1215\u001b[0m, in \u001b[0;36mPdfReader.get_object\u001b[0;34m(self, indirect_reference)\u001b[0m\n\u001b[1;32m   1213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m NullObject()\n\u001b[1;32m   1214\u001b[0m start \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxref[indirect_reference\u001b[38;5;241m.\u001b[39mgeneration][indirect_reference\u001b[38;5;241m.\u001b[39midnum]\n\u001b[0;32m-> 1215\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mseek\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1217\u001b[0m     idnum, generation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread_object_header(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream)\n",
      "\u001b[0;31mValueError\u001b[0m: seek of closed file"
     ]
    }
   ],
   "source": [
    "### Writing the extracted text to a new PDF \n",
    "\n",
    "page_one = pdf_reader_obj.pages[0]\n",
    "\n",
    "# init the writer\n",
    "writer = PyPDF2.PdfWriter()\n",
    "\n",
    "# add page to the writer \n",
    "writer.add_page(page_one) ## Add Page ## \n",
    "\n",
    "# read a dummy pdf \n",
    "pdf_out_bin = open(\"out.pdf\",\"wb\")\n",
    "\n",
    "writer.write(pdf_out_bin)\n",
    "\n",
    "pdf_out_bin.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_pdf(pdfs):\n",
    "    \n",
    "    merger = PyPDF2.PdfMerger()\n",
    "    \n",
    "    for pdf in pdfs:        \n",
    "        merger.append(pdf) # append \n",
    "        \n",
    "    bin_out = open(\"merger.pdf\",'wb')\n",
    "    merger.write(bin_out)\n",
    "    bin_out.close()\n",
    "    \n",
    "merge_pdf([\"out.pdf\", \"sample.pdf\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Word Embedding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word Embedding: representation of words as dense vectors in a continuous vector space, where the similarity between words is captured by the proximity of their respective vectors.\n",
    "\n",
    "- large corpora of text using unsupervised learning with techniques such as neural networks\n",
    "- Word embeddings capture the semantic and syntactic meaning of words based on the context in which they appear in the training data\n",
    "\n",
    "\n",
    "We could represent words as single integers, like \"hello\" = 1, \"world\" = 2, \"cat\" = 3, and so on. However, this approach has two major issues:\n",
    "\n",
    "1. Neural Network: Numerically Close == Semantically Close (Which is alwasys not the case!)\n",
    "\n",
    "2. Even if we managed to group similar words with close numbers, it would only capture similarity in one dimension. For instance, \"man\" and \"boy\" can be similar in gender but different in age or profession, which a single number can't fully represent.\n",
    "\n",
    "\n",
    "**Interpretation if Cos between embeddings:** \n",
    "\n",
    "Closer to 1: The sentences are likely to be very similar in meaning. <br>\n",
    "Around 0: The sentences are likely to be unrelated or neutral with respect to each other.<br>\n",
    "Closer to -1: The sentences might be expressing opposite meanings or concepts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| **Feature**              | **Word2Vec**                                    | **BERT**                                           |\n",
    "|--------------------------|-------------------------------------------------|----------------------------------------------------|\n",
    "| **Type**                 | Shallow, continuous bag-of-words (CBOW) or skip-gram model | Deep, bidirectional transformer-based model         |\n",
    "| **Context**              | Fixed-size window of words (limited context)    | Entire sentence or sequence (global context)        |\n",
    "| **Word Representation**  | Static word embeddings (single vector per word) | Contextualized word embeddings (different vectors depending on context) |\n",
    "| **Pre-training Objective** | Predicting surrounding words (CBOW) or the target word (Skip-gram) | Masked Language Model (MLM) and Next Sentence Prediction (NSP) |\n",
    "| **Architecture**         | Simple neural network with one hidden layer     | Multi-layer transformer (deep neural network)       |\n",
    "| **Handling Polysemy**    | Same vector for all senses of a word            | Different vectors based on the word's context       |\n",
    "| **Training Data**        | Typically trained on large corpora like Google News | Trained on large corpora like BooksCorpus and Wikipedia |\n",
    "| **Training Time**        | Relatively fast to train                        | Computationally expensive and time-consuming        |\n",
    "| **Performance**          | Good for basic similarity tasks                 | Superior for a wide range of NLP tasks (e.g., question answering, sentiment analysis) |\n",
    "| **Usage**                | Suitable for tasks like word similarity, sentiment analysis, etc. | State-of-the-art performance on various NLP benchmarks |\n",
    "| **Handling OOV Words**    | Cant handle out-of-vocabulary (OOV) words well | Can handle OOV words using subword tokenization (WordPiece) |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Feature**                | **BERT**                                             | **ELMo**                                                | **GPT**                                               |\n",
    "|----------------------------|------------------------------------------------------|---------------------------------------------------------|-------------------------------------------------------|\n",
    "| **Full Name**              | Bidirectional Encoder Representations from Transformers | Embeddings from Language Models                          | Generative Pre-trained Transformer                    |\n",
    "| **Architecture**           | Transformer-based, bidirectional                     | BiLSTM (Bidirectional Long Short-Term Memory)            | Transformer-based, unidirectional (left-to-right)     |\n",
    "| **Contextual Representation** | Contextualized, bidirectional                      | Contextualized, bidirectional                            | Contextualized, unidirectional (left-to-right)        |\n",
    "| **Pre-training Objectives** | - Masked Language Model (MLM) <br> - Next Sentence Prediction (NSP) | - Deep contextualized word representations <br> - Pretrained on `character-based language model` | - Language Modeling (predicting next word in sequence) |\n",
    "| **Training Data**          | BooksCorpus and English Wikipedia                    | 1 Billion Word Benchmark                                 | BooksCorpus (for GPT) / Diverse web text (for GPT-2)  |\n",
    "| **Word Embeddings**        | Contextual, changes depending on sentence            | Contextual, changes depending on sentence                | Contextual, changes depending on sentence              |\n",
    "| **Handling Polysemy**      | Effectively handles polysemy by creating different embeddings based on context | Effectively handles polysemy by creating different embeddings based on context | Effectively handles polysemy, but only in left-to-right context |\n",
    "| **Pre-training Method**    | Transformer-based with self-attention                | BiLSTM with character-level convolutions                 | Transformer-based with self-attention (autoregressive) |\n",
    "| **Fine-tuning**            | Yes, designed for fine-tuning on specific tasks      | Can be fine-tuned but typically used as a `feature extractor` | Yes, designed for fine-tuning on specific tasks       |\n",
    "| **Use Cases**              | State-of-the-art performance in many NLP tasks (e.g., QA, sentiment analysis) | Used as a feature extractor for various NLP tasks        | Strong performance in text generation and completion tasks |\n",
    "| **Context Window**         | Considers entire sentence context bidirectionally    | Considers entire sentence context bidirectionally        | Considers left-to-right context only                   |\n",
    "| **Training Complexity**    | High, requires substantial computational resources   | Moderate, but computationally less demanding than BERT   | High, similar to BERT, especially in later versions like GPT-2 |\n",
    "| **Performance**            | Generally superior in tasks requiring deep understanding of context | Effective in a variety of NLP tasks, but not as powerful as BERT or GPT in some cases | Strong in text generation, completion, and certain understanding tasks |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "sentece = \"I love Natrual Language Processing and I will score 90/100.\"\n",
    "\n",
    "tokens = word_tokenize(sentece)\n",
    "\n",
    "model = Word2Vec([tokens], vector_size = 100, window =5, min_count =1, sg = 0)\n",
    "\n",
    "print(\"Vocab:\\n\")\n",
    "print(list(model.wv.index_to_key))\n",
    "\n",
    "print(\"Word Vectors:\")\n",
    "for word in model.wv.index_to_key:\n",
    "    vector = model.wv[word]\n",
    "    # print(f\"Word: {word} Vector: {vector}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the vector for a word \n",
    "word = \"Apple\"\n",
    "\n",
    "if word in model.wv.index_to_key:\n",
    "    vec = model.wv[word]\n",
    "else:\n",
    "    vec = 0\n",
    "    \n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the similar \n",
    "word = \"love\"\n",
    "similarites = model.wv.most_similar(word, topn = 2)\n",
    "\n",
    "for w , sim in similarites:\n",
    "    print(w, sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save and load \n",
    "model.save(\"x.model\")\n",
    "model = Word2Vec.load(\"x.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "import torch \n",
    "from transformers import BertTokenizer, BertModel \n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "seed = 42 \n",
    "random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "if torch.cuda.is_available(): \n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    \n",
    "    \n",
    "    \n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The AIMT is a fantastic program at the lambton college.\"\n",
    "\n",
    "\n",
    "# \n",
    "# tokenizer (text , retun_tensor, padd..) -> {\"input_ids\":,\"attention_mask\"}\n",
    "# tokenizer.tokenize() # break to wordpiece 'subword': running -> run ##ing\n",
    "# tokenizer.decode(skip_special_tokens=True) : input_ids -> text\n",
    "# tokenizer.encode : text -> tokens\n",
    "\n",
    "encoding = tokenizer(text, return_tensors='pt', padding= True, truncation=False, max_length=64)\n",
    "input_ids = encoding[\"input_ids\"]\n",
    "attention_mask = encoding[\"attention_mask\"]\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    outputs = model(input_ids, attention_mask=attention_mask)\n",
    "    word_embedding = outputs.last_hidden_state\n",
    "    sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    \n",
    "print(f\"Shape of word embeddings: {word_embedding.shape}\")\n",
    "\n",
    "print(cosine_similarity(sentence_embedding,sentence_embedding))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded_text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "# the decoded text \n",
    "print(f\"Decoded Text : {decoded_text}\")\n",
    "\n",
    "tokenized_text = tokenizer.tokenize(decoded_text)\n",
    "\n",
    "print(f\"tokenized text {tokenized_text}\")\n",
    "\n",
    "encoded_text = tokenizer.encode(text, return_tensors=\"pt\")\n",
    "print(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
