{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "import plotly.graph_objs as go\n",
    "import plotly.express as px\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set(style=\"darkgrid\")\n",
    "sns.set_palette(sns.color_palette(\"viridis\"))\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold, KFold\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('WineQT.csv')\n",
    "\n",
    "# conver the columns into lowercase\n",
    "df.columns = [c.lower().replace(' ','_') for c in df.columns]\n",
    "# df['quality'] = df['quality'].apply(lambda x: x-3)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA \n",
    "\n",
    "Missing Values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Duplicated Values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nNumber of duplicated rows : \", df.drop(columns=['id']).duplicated().sum(),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(subset=['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "       'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "       'ph', 'sulphates', 'alcohol', 'quality'], keep='first')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. About 10% of rows were duplicated and has been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expected data types\n",
    "expected_dtypes = {\n",
    "    'fixed_acidity': 'float64',\n",
    "    'volatile_acidity': 'float64',\n",
    "    'citric_acid': 'float64',\n",
    "    'residual_sugar': 'float64',\n",
    "    'chlorides': 'float64',\n",
    "    'free_sulfur_dioxide': 'float64',\n",
    "    'total_sulfur_dioxide': 'float64',\n",
    "    'density': 'float64',\n",
    "    'ph': 'float64',\n",
    "    'sulphates': 'float64',\n",
    "    'alcohol': 'float64',\n",
    "    'quality': 'int64',\n",
    "    \"id\" : \"int64\"\n",
    "}\n",
    "\n",
    "# Check for incorrect data types\n",
    "incorrect_dtypes = {col: dtype for col, dtype in df.dtypes.items() if dtype != expected_dtypes[col]}\n",
    "\n",
    "print(\"Incorrect df types:\")\n",
    "print(None)\n",
    "\n",
    "# Convert to the correct df types if needed\n",
    "print(\"Data is correct with following:\")\n",
    "for col, dtype in incorrect_dtypes.items():\n",
    "    df[col] = df[col].astype(expected_dtypes[col])\n",
    "\n",
    "# Verify the conversion\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "           'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "           'ph', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "for feature in features:\n",
    "    plt.subplot(3, 4, features.index(feature) + 1)\n",
    "    sns.boxplot(data=df, y=feature, color='skyblue', width=0.5)\n",
    "    plt.title(f'Boxplot of {feature}')\n",
    "    plt.ylabel('')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_to_drop = 100 - 100*len(df[(df['residual_sugar']<=7) & (df['chlorides']<=0.4)])/len(df)\n",
    "\n",
    "print(f\"\\nDropping selected outliers will result in loss of {percent_to_drop:.2f} % of data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Outliers are present but seem to contain valuable information\n",
    "Most outliers are in<br>\n",
    "    1. residual_sugar<br>\n",
    "    2. chlorides<br>\n",
    "    3. sulphates<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Target Distribution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(data=df, x='quality', palette='Set2')\n",
    "plt.title('Distribution of Wine Quality')\n",
    "plt.xlabel('Wine Quality')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Correlations**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['fixed_acidity', 'volatile_acidity', 'citric_acid', 'residual_sugar',\n",
    "            'chlorides', 'free_sulfur_dioxide', 'total_sulfur_dioxide', 'density',\n",
    "            'ph', 'sulphates', 'alcohol', 'quality']\n",
    "\n",
    "correlation_data = df[features]\n",
    "\n",
    "correlation_matrix = correlation_data.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. No missing values\n",
    "\n",
    "2. About 10% of rows were duplicated and has been removed\n",
    "\n",
    "3. Outliers are present but seem to contain valuable information\n",
    "    Most outliers are in\n",
    "       1. residual_sugar\n",
    "       2. chlorides\n",
    "       3. sulphates\n",
    "We have removed a little bit of them that don't affect the quality with small number of data points:\n",
    "* removed data points where df['residual_sugar'] > 7\n",
    "* removed data points where df['chlorides'] > 0.4\n",
    "\n",
    "4. Best Quality Wine (4 and 5, we've shifted quality to be from 0 to 5)\n",
    "    Has highest\n",
    "       1. alcohol\n",
    "       2. citric_acid\n",
    "       3. sulphates\n",
    "    Has lowest\n",
    "       1. volatile_acidity\n",
    "       2. dencity\n",
    "       3. pH\n",
    "5. Dataset is unbalanced"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df['Total_sulphur_Dioxide'] = df['free_sulfur_dioxide'] + df['total_sulfur_dioxide']\n",
    "df = df.drop(columns = ['free_sulfur_dioxide','total_sulfur_dioxide'])\n",
    "df['Acidity'] = df['fixed_acidity'] + df['volatile_acidity'] + df['citric_acid']\n",
    "\n",
    "df = df.drop(columns = ['fixed_acidity','volatile_acidity','citric_acid'])\n",
    "\n",
    "def categorize_sugar(sugar):\n",
    "  if sugar< 1.5 :\n",
    "    return \"low\"\n",
    "  elif sugar >1.5 and sugar<7:\n",
    "    return \"medium\"\n",
    "  else:\n",
    "    return \"high\"\n",
    "  \n",
    "df['residual_sugar'] = df['residual_sugar'].apply(categorize_sugar)\n",
    "\n",
    "def categorize_pH(pH):\n",
    "  if pH<3:\n",
    "    return \"acidic\"\n",
    "  elif pH>=3 and pH<=4:\n",
    "    return \"neutral\"\n",
    "  else:\n",
    "    return \"basic\"\n",
    "\n",
    "df['ph'] = df['ph'].apply(categorize_pH)\n",
    "\n",
    "cate_cols = ['residual_sugar', 'ph']\n",
    "\n",
    "df = pd.get_dummies(df, columns=cate_cols)\n",
    "\n",
    "df[\"residual_sugar_high\"]= df[\"residual_sugar_high\"].astype(int)\n",
    "df[\"residual_sugar_low\"]= df[\"residual_sugar_low\"].astype(int)\n",
    "df[\"residual_sugar_medium\"]= df[\"residual_sugar_medium\"].astype(int)\n",
    "df[\"ph_acidic\"]= df[\"ph_acidic\"].astype(int)\n",
    "df[\"ph_basic\"]= df[\"ph_basic\"].astype(int)\n",
    "df[\"ph_neutral\"]= df[\"ph_neutral\"].astype(int)\n",
    "\n",
    "\n",
    "# Train test Split \n",
    "X=df.drop(\"quality\",axis=1)\n",
    "y=df['quality']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.drop(\"quality\",axis=1)\n",
    "y=df['quality']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings \n",
    "warnings.filterwarnings(action=\"ignore\")\n",
    "\n",
    "treeclassifier = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Hyperparameter Tuninig: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf2 = DecisionTreeClassifier()\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "accuracy2 = accuracy_score(y_pred2, y_test)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_accuracy2 = clf2.score(X_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy for DecisionTreeClassifier: \", train_accuracy2)\n",
    "print(\"Test Accuracy for DecisionTreeClassifier: \", accuracy2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Hyperparamter + Best Parameter: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters2 = {\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'splitter' : ['best','random'],\n",
    "    'max_depth' : [1,2,3,4,5],\n",
    "    'max_features' : ['auto','sqrt','log2']\n",
    "}\n",
    "\n",
    "clf2 = GridSearchCV(treeclassifier, param_grid = parameters2, cv=5,scoring='accuracy')\n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Extract the best parameters from the grid search\n",
    "best_params2 = clf2.best_params_\n",
    "\n",
    "# Refit the DecisionTreeClassifier with the best parameters\n",
    "clf2 = DecisionTreeClassifier(**best_params2)\n",
    "clf2.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred2 = clf2.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "accuracy2 = accuracy_score(y_pred2, y_test)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_accuracy2 = clf2.score(X_train, y_train)\n",
    "\n",
    "# Print the best parameters, training accuracy, and test accuracy\n",
    "print(\"Best parameters for DecisionTreeClassifier: \", best_params2)\n",
    "print(\"Training Accuracy for DecisionTreeClassifier: \", train_accuracy2)\n",
    "print(\"Test Accuracy for DecisionTreeClassifier: \", accuracy2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data with the same shape and features as X_train\n",
    "X_train_random = np.random.rand(X_train.shape[0], X_train.shape[1])\n",
    "\n",
    "print(f\"Random Data: {[X_train_random[0]]}\")\n",
    "# Make predictions on the random data\n",
    "y_pred_random = clf2.predict([X_train_random[0]])\n",
    "\n",
    "# Print predictions for the random data\n",
    "print(\"Predictions for random data: \", y_pred_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With the best prameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Without Hyperparamter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3__ = RandomForestClassifier()\n",
    "clf3__.fit(X_train,y_train)\n",
    "\n",
    "train_accuracy3 = clf3__.score(X_train, y_train)\n",
    "\n",
    "y_pred3 = clf3__.predict(X_test)\n",
    "accuracy3 = accuracy_score(y_test,y_pred3)\n",
    "\n",
    "print(\"Training Accuracy for RandomForestClassifier: \", train_accuracy3)\n",
    "\n",
    "print(\"Testing Accuracy for RandomForestClassifier:  : \" , accuracy3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With best paramters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3 =RandomForestClassifier()\n",
    "\n",
    "parameters3 = {\n",
    "    'criterion' : ['gini','entropy'],\n",
    "    'max_depth' : [1,2,3,4,5,6,7,8,9],\n",
    "    'n_estimators' : [1,10,100,200,300,500,1000]\n",
    "}\n",
    "clf3 = RandomizedSearchCV(clf3, param_distributions =parameters3, scoring='accuracy',cv=5,verbose=3)\n",
    "\n",
    "clf3.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "\n",
    "best_params3 = clf3.best_params_\n",
    "clf3__ = RandomForestClassifier(**best_params3)\n",
    "clf3__.fit(X_train,y_train)\n",
    "\n",
    "train_accuracy3 = clf3__.score(X_train, y_train)\n",
    "\n",
    "y_pred3 = clf3__.predict(X_test)\n",
    "accuracy3 = accuracy_score(y_test,y_pred3)\n",
    "\n",
    "print(\"Best parameters for Random_Forest : \",best_params3)\n",
    "print(\"Training Accuracy for RandomForestClassifier: \", train_accuracy3)\n",
    "\n",
    "print(\"Testing Accuracy for RandomForestClassifier:  : \" , accuracy3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data with the same shape and features as X_train\n",
    "X_train_random = np.random.rand(X_train.shape[0], X_train.shape[1])\n",
    "\n",
    "print(f\"Random Data: {[X_train_random[0]]}\")\n",
    "# Make predictions on the random data\n",
    "y_pred_random = clf3__.predict([X_train_random[0]])\n",
    "\n",
    "# Print predictions for the random data\n",
    "print(\"Predictions for random data: \", y_pred_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logstic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression()\n",
    "\n",
    "clf1.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred2 = clf1.predict(X_test)\n",
    "\n",
    "# Calculate the test accuracy\n",
    "accuracy2 = accuracy_score(y_pred2, y_test)\n",
    "\n",
    "# Calculate the training accuracy\n",
    "train_accuracy2 = clf1.score(X_train, y_train)\n",
    "\n",
    "print(\"Training Accuracy for LogisticRegression: \", train_accuracy2)\n",
    "print(\"Test Accuracy for LogisticRegression: \", accuracy2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters1 = {'penalty' : ['l1','l2','elasticnet','None'],'C':[1,5,10,20,50,75,100]}\n",
    "\n",
    "clf1 = GridSearchCV(clf1,param_grid=parameters1,cv=5)\n",
    "\n",
    "clf1.fit(X_train,y_train)\n",
    "\n",
    "train_accuracy1 = clf1.score(X_train, y_train)\n",
    "\n",
    "best_params = clf1.best_params_\n",
    "\n",
    "clf1 =LogisticRegression(C = best_params['C'], penalty = best_params['penalty'])\n",
    "\n",
    "\n",
    "clf1.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "y_pred1 = clf1.predict(X_test)\n",
    "accuracy = accuracy_score(y_pred1,y_test)\n",
    "print(\"Training Accuracy for LogisticRegression: \", train_accuracy1)\n",
    "print(\"Test Accuracy for LogisticRegression: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random data with the same shape and features as X_train\n",
    "X_train_random = np.random.rand(X_train.shape[0], X_train.shape[1])\n",
    "\n",
    "print(f\"Random Data: {[X_train_random[0]]}\")\n",
    "# Make predictions on the random data\n",
    "y_pred_random = clf1.predict([X_train_random[0]])\n",
    "\n",
    "# Print predictions for the random data\n",
    "print(\"Predictions for random data: \", y_pred_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
